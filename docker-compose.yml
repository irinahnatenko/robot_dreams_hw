

services:
  airflow:
    image: apache/airflow:2.8.1
    environment:
      AIRFLOW__CORE__EXECUTOR: SequentialExecutor
      AIRFLOW__CORE__LOAD_EXAMPLES: 'false'
    volumes:
      - ./dags:/opt/airflow/dags
      - ./spark_jobs:/opt/airflow/spark_jobs
      - ./data:/opt/airflow/data
      - /var/run/docker.sock:/var/run/docker.sock
    ports:
      - 8081:8080
    command: >
      bash -c "
      airflow db init &&
      airflow users create --username admin --password admin --firstname A --lastname B --role Admin --email admin@example.com &&
      airflow scheduler & airflow webserver
      "

  jupyter:
    image: jupyter/pyspark-notebook
    ports:
      - 8888:8888
    volumes:
      - ./data:/home/jovyan/data
      - ./spark_jobs:/home/jovyan/spark_jobs

  spark:
    image: jupyter/pyspark-notebook
    command: tail -f /dev/null
    volumes:
      - ./spark_jobs:/home/jovyan/spark_jobs
      - ./data:/home/jovyan/data